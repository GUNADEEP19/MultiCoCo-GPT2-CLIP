name: run_1_aokvqa_baseline
model_id: gpt2
seed: 42
bf16: false  # Not using bf16; using fp16 (via AMP)
project: coconut_aokvqa_guna

# âœ… Save checkpoints to Google Drive (persistent)
save_path: /content/drive/MyDrive/COCONUT/checkpoints/coconut_aokvqa_gunadeep
load_model_path: null
resume: 0
reset_optimizer: false
only_eval: false
save_only_improve: true

# âœ… Dataset paths (adjust if needed)
train_path: /content/MultiModal-COCONUT-GPT2-CLIP-/data/Datasets/A-OKVQA/aokvqa_train.json
val_path: /content/MultiModal-COCONUT-GPT2-CLIP-/data/Datasets/A-OKVQA/aokvqa_validation.json

# â›“ï¸ Reasoning setup
debug: false
no_thoughts: false
cot: false
no_cot: false
coconut: true

# ğŸ§  Curriculum configs
c_thought: 2
max_latent_stage: 8
epochs_per_stage: 2
pad_latent_to_max: true
uniform_prob: 0.1

# ğŸ‹ï¸ Training configs for Colab Free Tier
num_epochs: 25
batch_size_training: 1         # â¬…ï¸ CHANGED from 2 â†’ 1 (reduces GPU memory usage)
gradient_accumulation_steps: 2 # â¬…ï¸ ADDED to simulate batch size of 2
lr: 5e-5
weight_decay: 0.0
