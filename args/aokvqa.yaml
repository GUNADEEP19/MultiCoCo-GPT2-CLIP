name: run_1_aokvqa_baseline
model_id: llava-hf/llava-1.5-7b-hf
seed: 42
bf16: true
project: Coconut_Aokvqa_Guna_LLaVA-1.5-7B

# âœ… Save checkpoints to Google Drive (persistent)
save_path: /content/drive/MyDrive/COCONUT/checkpoints/coconut_aokvqa_gunadeep
load_model_path: null
resume: 0
reset_optimizer: false
only_eval: false
save_only_improve: true

# âœ… Dataset paths (adjust if needed)
train_path: /content/MultiModal-COCONUT-GPT2-CLIP-/data/Datasets/A-OKVQA/aokvqa_train.json
val_path: /content/MultiModal-COCONUT-GPT2-CLIP-/data/Datasets/A-OKVQA/aokvqa_validation.json

# ğŸ§  Curriculum configs
c_thought: 1             # Try 1 for fewer latent tokens per step
uniform_prob: 0.1

# ğŸ§  Latent-space configs (REQUIRED for EM-style training)
latent_dim: 4096  # âœ… Matches LLaVA-1.5-7B hidden size
# n_latents: 4              # Number of latent tokens per sample
latent_lr: 1e-3           # Learning rate for latent vectors (E-step)
e_steps: 3                # Number of E-step optimization steps per batch

# ğŸ‹ï¸ Training configs for Colab Free Tier
num_epochs: 28
batch_size_training: 48         # Increased for A100 GPU (was 8)
gradient_accumulation_steps: 1 # No accumulation needed for A100, batch size 32
lr: 1e-4
weight_decay: 0.0

# ğŸš€ Optional Optimizations (uncomment to enable)
# load_4bit: true              # 4-bit quantization (requires bitsandbytes)
# use_flash_attention_2: true  # Flash Attention 2 (requires flash-attn)

max_length: 512  # Optimal for A-OKVQA, fits all data, saves memory
max_latent_stage: 7           # Curriculum: number of latent stages
epochs_per_stage: 4           # Curriculum: epochs per stage
